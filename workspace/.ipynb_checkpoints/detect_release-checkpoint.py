"""
detect_release.py
ğŸ‘‰ åµæ¸¬å‡ºæ‰‹å¹€ï¼ˆrelease frameï¼‰ï¼Œä½¿ç”¨ Detectron2 è¼¸å‡ºçš„ pixel keypointsã€‚
"""

import os
import cv2
import numpy as np
import json
from pose_utils_detectron2 import calculate_pixel_angle_from_points

OUTPUT_DIR = "output_release"
os.makedirs(OUTPUT_DIR, exist_ok=True)
OUTPUT_JSON = os.path.join(OUTPUT_DIR, "release_frame.json")


def detect_release(pose_sequence, output_json=OUTPUT_JSON):
    """
    æ ¹æ“šé—œéµé»æ¢ä»¶èˆ‡è§’åº¦è¨ˆç®—å‡ºæ‰‹å¹€ã€‚
    - pose_sequence: listï¼Œæ¯å¹€åŒ…å« 'frame' å’Œ 'keypoints'
    å›å‚³æœ€ä½³å‡ºæ‰‹ frame ç·¨è™Ÿ
    """

    candidate_frames = []

    for item in pose_sequence:
        frame_idx = item["frame"]
        keypoints = item["keypoints"]  # (17, 3)
        if keypoints.shape[0] < 17:
            continue

        # é—œéµé»ä¿¡å¿ƒå€¼éæ¿¾
        if np.min(keypoints[[11, 12, 14, 16], 2]) < 0.3:
            continue

        right_shoulder = keypoints[12]
        left_shoulder = keypoints[11]
        right_elbow = keypoints[14]
        right_wrist = keypoints[16]

        # åŸºæœ¬é‡
        shoulder_dist = abs(right_shoulder[0] - left_shoulder[0])
        print(frame_idx, ":", shoulder_dist, right_wrist[1], right_shoulder[1])

        elbow_angle = calculate_pixel_angle_from_points(
            right_wrist[:2], right_elbow[:2], right_shoulder[:2]
        )

        shoulder_vec = np.array(
            [right_shoulder[0] - left_shoulder[0], right_shoulder[1] - left_shoulder[1]]
        )
        horizontal_vec = np.array([1, 0])
        cos_theta = np.dot(shoulder_vec, horizontal_vec) / np.linalg.norm(shoulder_vec)
        shoulder_angle = np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))

        # å‡ºæ‰‹æ¢ä»¶
        if shoulder_dist > 25 and right_wrist[1] > right_shoulder[1]:
            candidate_frames.append(
                {
                    "frame": frame_idx,
                    "elbow_angle": elbow_angle,
                    "shoulder_angle": shoulder_angle,
                    "shoulder_dist": shoulder_dist,
                }
            )
        # å‡ºæ‰‹æ¢ä»¶ä¸æ»¿è¶³
        else:
            print('å‡ºæ‰‹æ¢ä»¶ä¸æ»¿è¶³')

    if not candidate_frames:
        print("âš ï¸ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„ç•«é¢")
        return None

    # é¸å‡º shoulder_angle æœ€å°çš„å‰ä¸‰å¹€
    top3 = sorted(candidate_frames, key=lambda f: f["shoulder_angle"])[:3]
    print(top3)

    def compute_score(f):
        return -1.5 * f["shoulder_angle"] + 0.8 * f["elbow_angle"]

    best_frame = max(top3, key=compute_score)
    frame_id = best_frame["frame"]

    # å„²å­˜ json
    with open(output_json, "w") as f:
        json.dump({"release_frame": frame_id}, f, indent=2)
    print(f"ğŸ“¸ å·²å„²å­˜å‡ºæ‰‹è³‡è¨Šï¼š{output_json}")

    return frame_id


if __name__ == "__main__":
    from pose_utils_detectron2 import load_pose_sequence

    pose_sequence = load_pose_sequence("output_detectron2_first_person_tracked")
    result = detect_release(pose_sequence)
    print(f"âœ… å‡ºæ‰‹åµæ¸¬çµæœï¼š{result}")
